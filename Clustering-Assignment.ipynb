{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT2101 K-Means and Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Goal\n",
    "\n",
    "In this notebook, we will explore clustering method, an unsupervised learning method, including:\n",
    "* K-Means Clustering\n",
    "* Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means Clustering steps:\n",
    "\n",
    "1. Determine the number of k (i.e., number of clusters)\n",
    "2. Randomly select k centroids (i.e. centers of clusters)\n",
    "3. Assign each data point to its closest centroid\n",
    "4. Recalculate the centroids as the average of all data points in a cluster\n",
    "5. Assign data points to their closest centroids\n",
    "6. Repeat Step 4 and 5 until the observations are not reassigned or the maximum number of iterations is reached\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load data\n",
    "filepath = './iris.csv'\n",
    "colnames = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "feature_list =  ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "#iris = pd.read_csv(filepath, header=None, names=colnames, dtype={'sepal_length':np.float64, 'sepal_width':np.float64, 'petal_length':np.float64, 'petal_width':np.float64})\n",
    "iris = pd.read_csv(filepath)\n",
    "features = iris[feature_list]\n",
    "\n",
    "# Standardize features: Z-index\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit k-means clustering model: Suppose 3 clusters\n",
    "cluster_3 = KMeans(n_clusters=3, random_state=0, n_jobs=-1)\n",
    "model_3 = cluster_3.fit(features) # Clustering without feature standardization\n",
    "model_std_3 = cluster_3.fit(features_std) # Clustering after feature standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13597027,  0.09659843,  0.996271  ,  1.01717187],\n",
       "       [-1.01457897,  0.84230679, -1.30487835, -1.25512862],\n",
       "       [-0.05021989, -0.88029181,  0.34753171,  0.28206327]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View cluster centers for each cluster:\n",
    "model_std_3.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View predicted clusters:\n",
    "model_std_3.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with true classes:\n",
    "# Remember usually you have no output labels in the dataset used for clustering\n",
    "iris['species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict which cluster is a new observation in:\n",
    "new_obs = [[0.5, 0.5, 0.5, 0.5]]\n",
    "model_std_3.predict(new_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose k? \n",
    "#### Elbow method\n",
    "* Gauge how the heterogeneity within clusters changes for various of k.\n",
    "* The heterogeneity within clusters is expected to decreases with more clusters.\n",
    "* The heterogeneity is measured by within-clusters/groups sum of squares (WSS)\n",
    "\n",
    "\\begin{align}\n",
    "WSS(k) = \\mathop{\\sum}_{i=1}^{N}\\mathop{\\sum}_{j=0}^{p}(x_{ij}-centroid(x_{kj}))^2\n",
    "\\end{align}\n",
    "\n",
    "Suppose N observations and p features. <br/>\n",
    "k is cluster id ($=1,...,K$). <br/>\n",
    "$x_{ij}$ is $i^{th}$ observation $j^{th}$ feature. <br/>\n",
    "$centroid(x_{kj})$ is $k^{th}$ centroid of feature $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scipy used for calculate distances\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster data with 1-10 clusters and get centroids\n",
    "\n",
    "N_cluster = range(1, 11) # Assume number of 1 to 10 clusters\n",
    "WSS_list = [] # A list of WSS for 1 to 10 clusters\n",
    "\n",
    "for k in N_cluster:\n",
    "    \n",
    "    # Run k-means model\n",
    "    cluster = KMeans(n_clusters=k, random_state=0, n_jobs=-1) # Run the model with k clusters: k from 1 to 10\n",
    "    model = cluster.fit(features_std) # Fit the data with standardized features\n",
    "    centroids = model.cluster_centers_ # Get centroids for each cluster id (=0,...,k-1)\n",
    "    labels = model.labels_ # Get labels (which cluster id) for each observation\n",
    "    \n",
    "    # Calculate WSS(k)\n",
    "    squared_distance = cdist(features_std, centroids, 'sqeuclidean') # Calculate squared distance between each observation and k centroids\n",
    "    #min_distance_cluster_id = np.argmin(squared_distance, axis=1) # Find the index of minimum squared distance for each observation\n",
    "    min_distance = np.min(squared_distance, axis=1) # Find minimum squared distance for each observation\n",
    "    WSS = np.sum(min_distance)\n",
    "    \n",
    "    WSS_list.append(WSS)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show WSS for 1-10 clusters\n",
    "WSS_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow curve\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(N_cluster, WSS_list, 'g*-')\n",
    "ax.plot(N_cluster[1], WSS_list[1], marker='o', markersize=12, markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "ax.plot(N_cluster[2], WSS_list[2], marker='o', markersize=12, markeredgewidth=2, markeredgecolor='b', markerfacecolor='None')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Within-cluster Sum of Squares (WSS)')\n",
    "plt.title('Elbow curve for K-means clustering')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you choose k=3, you can use pairplot to visualize the differences of these 3 clusters in terms of their attributes\n",
    "\n",
    "References: https://seaborn.pydata.org/generated/seaborn.pairplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "\n",
    "# Run k-means model\n",
    "cluster = KMeans(n_clusters=3, random_state=0, n_jobs=-1)\n",
    "y_pred = cluster.fit_predict(features_std) \n",
    "\n",
    "data = deepcopy(iris[feature_list])\n",
    "data['cluster'] = y_pred\n",
    "sns.pairplot( data, hue='cluster', diag_kind='kde', markers=['o','s','D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original codes can be found at http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical Clustering Steps:\n",
    "\n",
    "1. Start with n clusters (each record is its own cluster)\n",
    "2. Merge two closest records into one cluster\n",
    "3. At each successive step, the two clusters closest to each other are merged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meanshift object\n",
    "HC = AgglomerativeClustering(n_clusters=3)\n",
    "HC_model = HC.fit(features_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show clusters\n",
    "HC_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dendrogram for hierarchical clustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "avg_link = linkage(features_std[1:20, :], method='average') # Linkage criterion: average distance\n",
    "dendrogram(avg_link).items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about hierarchical clustering can be found at: <br/>\n",
    "[1] http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html <br/>\n",
    "[2] https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Assignments on K-Means Clustering (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this assignment is to know how to use scikit-learn package to do K-Means clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "This case requires to develop a customer segmentation to define marketing strategy. The sample Dataset summarizes the usage behavior of about 9000 active credit card holders during the last 6 months. The file is at a customer level with 18 behavioral variables.The dataset can be downloaded here (https://www.kaggle.com/arjunbhasin2013/ccdata/home). It is released under [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load data\n",
    "feature_list = ['BALANCE', 'PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS']\n",
    "creditcard = pd.read_csv('./CC GENERAL.csv')[['CUST_ID']+feature_list]\n",
    "creditcard.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard.dropna(inplace=True)\n",
    "creditcard.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1. Standardize all the features using `min-max` method (2 points)\n",
    "\n",
    "An example of standardizing features using `z-index` method:\n",
    "```python\n",
    "# Standardize features: z-index standardization\n",
    "feature_list = ['BALANCE', 'PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS']\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(creditcard[feature_list])\n",
    "```\n",
    "\n",
    "References: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features: min-max standardization\n",
    "feature_list = ['BALANCE', 'PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS']\n",
    "\n",
    "# Initialize a min-max scaler object to do standardization\n",
    "# Standardize features using min-max method\n",
    "scaler = MinMaxScaler()\n",
    "features_std = scaler.fit_transform(creditcard[feature_list])\n",
    "features_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. Fit 5-means clustering model with min-max standardized features: k=5 (2 points)\n",
    "Please:\n",
    "* Set `n_clusters=5`\n",
    "* Set `random_state=12345`\n",
    "* Set `n_jobs=-1` (This may not be necessary)\n",
    "\n",
    "References: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 5-means clustering model: Suppose 5 clusters k=5\n",
    "# Create a KMeans clustering model\n",
    "# Do clustering on min-max standardized features\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=12345).fit(features_std)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3. Predict which cluster does a new data sample belong to (1 point)\n",
    "\n",
    "* Suppose new data sample `new_obs=[[40, 90, 100, 1000, 1500, 50]]`\n",
    "* Use `predict` function\n",
    "* References: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of cluster centers\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict which cluster is this new observation in:\n",
    "new_obs = [[40, 90, 100, 1000, 1500, 50]]\n",
    "\n",
    "kmeans.predict(new_obs) # New data sample belongs to cluster index 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 References\n",
    "[1] Raschka, S. (2015). Python machine learning. Packt Publishing Ltd. <br/>\n",
    "[2] Chris Albon. (2018). Machine Learning with Python Cookbook. O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
